import os
import random
import shutil
from glob import glob
import numpy as np
from PIL import Image, UnidentifiedImageError

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models

from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
from tqdm.auto import tqdm  # æ›´æ™ºèƒ½çš„è¿›åº¦æ¡ï¼ˆWindows/ç»ˆç«¯/Notebookå‡å¯ï¼‰

# ========== åŸºæœ¬è®¾ç½® ==========
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

# å½“å‰è„šæœ¬ç›®å½•ï¼ˆå’Œä½ ä¹‹å‰çš„ä»£ç åŒç›®å½•ï¼‰
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# æºæ•°æ®ï¼ˆå››èŠ±è‰²æ•´ç‰Œå›¾åƒï¼‰ä¸åˆ’åˆ†åæ•°æ®é›†ç›®å½•ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
SRC_ROOT = os.path.normpath(os.path.join(BASE_DIR, "../PokerImage/dataset/suit"))
DST_ROOT = os.path.normpath(os.path.join(BASE_DIR, "../PokerImage/dataset_suit_split"))

ALLOWED_CLASSES = ["heart", "diamond", "spade", "club"]  # åªåšå››èŠ±è‰²
SPLITS = (0.7, 0.15, 0.15)  # train/val/test

IMG_EXTS = (".jpg", ".jpeg", ".png", ".bmp")

# è®­ç»ƒå‚æ•°
BATCH_SIZE = 32
NUM_EPOCHS = 15
LR = 1e-4
NUM_WORKERS = 0 if os.name == "nt" else 4  # Windows ä¸‹ç”¨ 0ï¼Œé¿å…å¤šè¿›ç¨‹é—®é¢˜
IMG_SIZE = 224
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æ˜¯å¦å¼ºåˆ¶é‡å»ºåˆ’åˆ†ç›®å½•ï¼ˆè®¾ä¸º True ä¼šåˆ é™¤å¹¶é‡å»º dataset_suit_split/ï¼‰
FORCE_RESPLIT = False


def safe_mkdir(path):
    os.makedirs(path, exist_ok=True)


def collect_images_by_class(src_root, allowed_classes):
    """é€ç±»æ”¶é›†æ–‡ä»¶è·¯å¾„ï¼Œå¹¶è¿‡æ»¤åå›¾åƒ"""
    class_to_files = {}
    for cls in allowed_classes:
        cls_dir = os.path.join(src_root, cls)
        if not os.path.isdir(cls_dir):
            print(f"âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°ç±»åˆ«ç›®å½• {cls_dir}ï¼Œå°†è·³è¿‡è¯¥ç±»ã€‚")
            class_to_files[cls] = []
            continue
        files = []
        for ext in IMG_EXTS:
            files.extend(glob(os.path.join(cls_dir, f"*{ext}")))
            files.extend(glob(os.path.join(cls_dir, f"*{ext.upper()}")))
        # è¿‡æ»¤æŸåå›¾ç‰‡
        good_files = []
        for fp in files:
            try:
                with Image.open(fp) as im:
                    im.verify()
                good_files.append(fp)
            except (UnidentifiedImageError, OSError):
                print(f"åå›¾åƒæˆ–æ— æ³•è¯»å–ï¼Œå·²è·³è¿‡ï¼š{fp}")
        random.shuffle(good_files)
        class_to_files[cls] = good_files
    return class_to_files


def split_and_copy(class_to_files, dst_root, splits=(0.7, 0.15, 0.15)):
    """æŒ‰ç±»åˆ«åˆ†å±‚åˆ’åˆ†å¹¶å¤åˆ¶åˆ° train/val/testï¼ˆå¸¦æ€»è¿›åº¦æ¡ + æ¯ç±»å°è¿›åº¦ï¼‰"""
    if FORCE_RESPLIT and os.path.isdir(dst_root):
        shutil.rmtree(dst_root)

    train_root = os.path.join(dst_root, "train")
    val_root   = os.path.join(dst_root, "val")
    test_root  = os.path.join(dst_root, "test")
    for root in [train_root, val_root, test_root]:
        for cls in ALLOWED_CLASSES:
            safe_mkdir(os.path.join(root, cls))

    t_ratio, v_ratio, _ = splits

    # è®¡ç®—æ•´ä½“æ–‡ä»¶æ•°ï¼Œç”¨ä¸€ä¸ªæ€»è¿›åº¦æ¡
    total_files = sum(len(v) for v in class_to_files.values())
    pbar_total = tqdm(total=total_files, desc="ğŸ“¦ åˆ’åˆ†å¹¶å¤åˆ¶åˆ° dataset_suit_split", unit="å›¾", dynamic_ncols=True)

    for cls, files in class_to_files.items():
        n = len(files)
        n_train = int(n * t_ratio)
        n_val   = int(n * v_ratio)
        n_test  = n - n_train - n_val
        idx_train = list(range(0, n_train))
        idx_val   = list(range(n_train, n_train + n_val))
        idx_test  = list(range(n_train + n_val, n))

        # æ¯ä¸€ç±»å†ç»™ä¸€ä¸ªå°è¿›åº¦æ¡
        for split_name, idxs, root in [
            ("train", idx_train, train_root),
            ("val",   idx_val,   val_root),
            ("test",  idx_test,  test_root),
        ]:
            desc = f"{cls:7s} â†’ {split_name:5s}"
            for i in tqdm(idxs, desc=desc, leave=False, dynamic_ncols=True):
                src_fp = files[i]
                basename = os.path.basename(src_fp)
                dst_fp = os.path.join(root, cls, basename)
                if not os.path.exists(dst_fp):
                    shutil.copy2(src_fp, dst_fp)
                pbar_total.update(1)

    pbar_total.close()

    # æ‰“å°å„åˆ’åˆ†æ•°é‡
    def count_images(root):
        total = 0
        per_cls = {}
        for cls in ALLOWED_CLASSES:
            c = sum(1 for e in os.scandir(os.path.join(root, cls)) if e.is_file())
            per_cls[cls] = c
            total += c
        return total, per_cls

    for split in ["train", "val", "test"]:
        total, per_cls = count_images(os.path.join(dst_root, split))
        print(f"{split.upper():5s} æ€»æ•°: {total} | é€ç±»: {per_cls}")


def get_dataloaders(dst_root, img_size=224, batch_size=32, num_workers=0):
    # æ•°æ®å¢å¼ºä¸é¢„å¤„ç†ï¼ˆImageNet å½’ä¸€åŒ–ï¼‰
    train_tf = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])
    eval_tf = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])

    train_dir = os.path.join(dst_root, "train")
    val_dir   = os.path.join(dst_root, "val")
    test_dir  = os.path.join(dst_root, "test")

    train_set = datasets.ImageFolder(train_dir, transform=train_tf)
    val_set   = datasets.ImageFolder(val_dir,   transform=eval_tf)
    test_set  = datasets.ImageFolder(test_dir,  transform=eval_tf)

    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,
                              num_workers=num_workers, pin_memory=True)
    val_loader   = DataLoader(val_set,   batch_size=batch_size, shuffle=False,
                              num_workers=num_workers, pin_memory=True)
    test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False,
                              num_workers=num_workers, pin_memory=True)

    return train_loader, val_loader, test_loader, train_set.classes


def build_model(num_classes):
    # ResNet18 è¿ç§»å­¦ä¹ 
    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, num_classes)
    return model


def train_one_epoch(model, loader, criterion, optimizer, device, epoch, total_epochs):
    model.train()
    running_loss, correct, total = 0.0, 0, 0
    pbar = tqdm(loader, desc=f"ğŸ§  Train {epoch}/{total_epochs}", dynamic_ncols=True)
    for imgs, labels in pbar:
        imgs, labels = imgs.to(device), labels.to(device)

        optimizer.zero_grad()
        logits = model(imgs)
        loss = criterion(logits, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * imgs.size(0)
        preds = torch.argmax(logits, dim=1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

        avg_loss = running_loss / total if total > 0 else 0.0
        acc = correct / total if total > 0 else 0.0
        pbar.set_postfix(avg_loss=f"{avg_loss:.4f}", acc=f"{acc:.4f}")
    return running_loss / total, correct / total


def eval_one_epoch(model, loader, criterion, device, epoch, total_epochs, phase="Val"):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0
    pbar = tqdm(loader, desc=f"ğŸ” {phase} {epoch}/{total_epochs}", dynamic_ncols=True)
    with torch.no_grad():
        for imgs, labels in pbar:
            imgs, labels = imgs.to(device), labels.to(device)
            logits = model(imgs)
            loss = criterion(logits, labels)
            running_loss += loss.item() * imgs.size(0)
            preds = torch.argmax(logits, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

            avg_loss = running_loss / total if total > 0 else 0.0
            acc = correct / total if total > 0 else 0.0
            pbar.set_postfix(avg_loss=f"{avg_loss:.4f}", acc=f"{acc:.4f}")
    return running_loss / total, correct / total


def plot_confusion_matrix(cm, classes, save_path):
    fig = plt.figure(figsize=(6, 5))
    plt.imshow(cm, interpolation='nearest')  # é»˜è®¤é…è‰²
    plt.title("Confusion Matrix")
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45, ha="right")
    plt.yticks(tick_marks, classes)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()
    fig.savefig(save_path, dpi=200)
    plt.close(fig)


def main():
    # 1) æ”¶é›† & åˆ’åˆ† & å¤åˆ¶ï¼ˆå¸¦æ€»è¿›åº¦æ¡ï¼‰
    class_to_files = collect_images_by_class(SRC_ROOT, ALLOWED_CLASSES)
    split_and_copy(class_to_files, DST_ROOT, SPLITS)

    # 2) DataLoader
    train_loader, val_loader, test_loader, classes = get_dataloaders(
        DST_ROOT, img_size=IMG_SIZE, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS
    )
    num_classes = len(classes)
    print(f"ç±»åˆ«é¡ºåºï¼š{classes}")

    # 3) æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    model = build_model(num_classes).to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    best_val_acc = 0.0
    best_model_path = os.path.join(BASE_DIR, "best_suit_resnet18.pth")

    # 4) è®­ç»ƒï¼ˆå¤–å±‚ epoch è¿›åº¦æ¡ï¼‰
    epoch_bar = tqdm(range(1, NUM_EPOCHS + 1), desc="ğŸ“ˆ Epochs", dynamic_ncols=True)
    for epoch in epoch_bar:
        tr_loss, tr_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, epoch, NUM_EPOCHS)
        va_loss, va_acc = eval_one_epoch(model, val_loader, criterion, DEVICE, epoch, NUM_EPOCHS, phase="Val")

        # åœ¨ epoch è¿›åº¦æ¡ä¸Šæ˜¾ç¤ºæ±‡æ€»æŒ‡æ ‡
        epoch_bar.set_postfix(tr_acc=f"{tr_acc:.4f}", va_acc=f"{va_acc:.4f}")

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if va_acc > best_val_acc:
            best_val_acc = va_acc
            torch.save(model.state_dict(), best_model_path)

    print(f"âœ… è®­ç»ƒå®Œæˆã€‚æœ€ä½³éªŒè¯å‡†ç¡®ç‡ï¼š{best_val_acc:.4f}ï¼Œæ¨¡å‹å·²ä¿å­˜ï¼š{best_model_path}")

    # 5) æµ‹è¯•é›†è¯„ä¼°
    model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))
    model.eval()

    all_preds, all_labels = [], []
    with torch.no_grad():
        for imgs, labels in tqdm(test_loader, desc="ğŸ§ª Test", dynamic_ncols=True):
            imgs = imgs.to(DEVICE)
            logits = model(imgs)
            preds = torch.argmax(logits, dim=1).cpu().numpy()
            all_preds.extend(list(preds))
            all_labels.extend(list(labels.numpy()))

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    test_acc = (all_preds == all_labels).mean()

    print("\n======== æµ‹è¯•é›†ç»“æœ ========")
    print(f"Test Accuracy: {test_acc:.4f}")
    print(classification_report(all_labels, all_preds, target_names=classes, digits=4))

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)
    cm_path = os.path.join(BASE_DIR, "confusion_matrix_suit.png")
    plot_confusion_matrix(cm, classes, cm_path)
    print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜ï¼š{cm_path}")


if __name__ == "__main__":
    main()
